library(haven)
Pima <- read_sav("Desktop/School Stuff/PIMA/Pima.sav")
View(Pima)
read(Pima)
getwd()
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
install.packages("ggplot2")
install.packages(c("caret", "caretEnsemble", "psyh", "Amelia", "mice", "GGally", "rpart", "randomForest", "knitr", "Hmisc", "e1071", "naivebayes", "RColorBrewer", "dplyr", "foreign"))
getwd()
library(tidyverse)
library(caret)
library(caretEnsemble)
install.packages("psych")
library(psych)
library(Amelia)
library(mice)
library(GGally)
library(rpart)
library(randomForest)
library(knitr)
library(Hmisc)
library(e1071)
library(naivebayes)
library(RColorBrewer)
library(foreign)
data <- read.spss ("Pima.sav", to data.frame=TRUE)
data <- read_sav("Desktop/School Stuff/PIMA/Pima.sav")
print(Pima)
print(str(Pima))
print(summary(Pima))
set.seed(1234)
ind <- sample(2, nrow(Pima), replace=T, prob=c(0.8, 0.2))
train <-Pima[ind==1,]
test <- Pima[ind==2,]
set.seed(2222)
rfPima <-randomForest(Outcome~., Pima=train)
rfPima <-randomForest(Outcome~., data=train)
rfPima <-randomForest(Outcome~., data=train)
set.seed(2222)
rfH <- randomForest(Outcome~., Pima=train)
View(rfPima)
View(rfPima)
library(randomForest)
rfNews()
library(psych)
library(RColorBrewer)
library(Amelia)
library(dplyr)
library(e1071)
library(foreign)
library(GGally)
library(Hmisc)
library(knitr)
library(naivebayes)
library(rpart)
library(tidyr)
library(tidyverse)
library(haven)
Pima <- read_sav("Desktop/School Stuff/PIMA/Pima.sav")
View(Pima)
load("/Users/senelisiwemuradzikwa/Desktop/School Stuff/PIMA/ATT17652.RData")
View(pimaindiandiabetes)
View(data)
print(data)
print(str(data))
set.seed(1234)
ind <- sample(2, nrow(data), replace= T, prob =c(0.8, 0.2))
train <- data[ind==1,]
test <- data[ind==2,]
set.seed(2222)
rfPima <-randomForest(Outcome~., data=train)
print(print(rfPima))
print(rfPima$confusion)
p1 <- predict(rfPima, train)
head(p1)
head(train$Outcome)
print(head(p1))
print(head(train$Outcome))
print(confusionMatrix(p1, train$Outcome))
install.packages("ConfusionTableR")
library(ConfusionTableR)
print(confusionMatrix(p1, train$Outcome))
print(confusion(p1,train$Outcome))
print(confusionTableR(p1,train$Outcome))
library(Amelia)
library(caretEnsemble)
library(dplyr)
library(e1071)
library(foreign)
library(ggplot2)
library(Hmisc)
library(KernSmooth)
library(knitr)
library(naivebayes)
library(psych)
library(randomForest)
library(RColorBrewer)
library(tidyverse)
print(data)
print(str(data))
print(summary(data))
set.seed(1234)
ind <-sample(2, nrow(data),replace=T, prob=c(0.8,0.2))
train <- data[ind==1,]
test <-data[ind==2,]
set.seed(2222)
rfPima<-randomForest(Outcome~., data=train)
print(print(rfPima))
print(attributes(rfPima))
print(rfPima$confusion)
p1<-predict(rfPima, train)
head(p1)
head(train$Outcome)
print(head(p1))
print(head(train$Outcome))
print(p1,train$Outcome)
library(ConfusionTableR)
confusionMatrix(train$Outcome, p1)
library(caret)
confusionMatrix(train$Outcome, p1)
library(tidyverse)
library(ggplot2)
library(caret)
library(caretEnsemble)
library(psych)
library(Amelia)
library(mice)
library(GGally)
library(rpart)
library(randomForest)
library(knitr)
library(Hmisc)
library(e1071)
library(naivebayes)
library(RColorBrewer)
library(dplyr)
library(foreign)
print(data)
print(str(data))
print(summary(data))
set.seed(1234)
ind <- sample(2, nrow(data), replace=T, prob=c(0.8, 0.2))
train <- data[ind==1,]
test<- data[ind==2,]
set.seed(2222)
rfPima<-randomForest(Outcome~., data=train)
print(print(rfPima))
print(attributes(rfPima))
print(rfPima$confusion)
p1<-predict(rfPima, train)
head(p1)
head(train$Outcome)
print(head(p1))
print(head(train$Outcome))
print(confusionMatrix(p1, train$Outcome))
p2<-predict(rfPima, test)
print(head(p2))
print(head(test$Outcome))
print(confusionMatrix(p2, test$Outcome))
plot(rfPima)
t <-tuneRF(train[,-10], train[,10], stepFactor = 1, plot=TRUE,ntreeTry = 300, trace = TRUE, improve = 0.05)
View(t)
print(rfPima<-randomForest(Outcome~.,data=train, ntree=300,mtry=2,importance=TRUE, proximity=TRUE))
print(print(rfPima))
print(rfPima<-randomForest(Outcome~.,data=train, ntree=300,mtry=3,importance=TRUE, proximity=TRUE))
print(rfPima<-randomForest(Outcome~.,data=train, ntree=300,mtry=2,importance=TRUE, proximity=TRUE))
print(print(rfPima))
p1<-predict(rfPima, train)
print(confusionMatrix(p1, train$Outcome))
p2<-predict(rfPima, test)
print(confusionMatrix(p2,test$Outcome))
plot(rfPima)
plot(t)
hist(treesize(rfPima), main = "Number of Nodes for the trees for Pima", col = "purple")
varImpPlot(rfPima)
varImpPlot(rfPima, sort=T,n.var=5, main="Top 5 variable importance for PIMA")
hist(treesize(rfPima), main = "Number of Nodes for the trees for PIMA", col = "purple")
print(importance(tfPima))
print(importance(rfPima))
print(varUsed(rfPima))
partialPlot(rfPima, train, Glucose, "0")
partialPlot(rfPima, train, Glucose, "1")
partialPlot(rfPima, train, BMI, "0")
partialPlot(rfPima, train, BMI, "1")
partialPlot(rfPima, train, Age, "0")
partialPlot(rfPima, train, Age, "1")
print(getTree(rfPima, 1, labelVar = TRUE))
MDSplot(rfPima, train$Outcome)
sink()
dev.off()
View(Pima)
View(Pima)
print(confusionMatrix(train$Outcome,p1))
str(data)
pairs.panels(data[-10])
data %>% ggplot(aes(x=Outcome, y=Pregnancies, fill=Outcome))geom_boxplot()+ggtitle("Boxplot of Pregnancies for PIMA data")
ggplot(aes(x=Outcome, y=Pregnancies, fill=Outcome))geom_boxplot()+ggtitle("Boxplot of Pregnancies for PIMA data")
data %>%
ggplot(aes(x=Outcome, y=Pregnancies, fill=Outcome))geom_boxplot()+ggtitle("Boxplot of Pregnancies for PIMA data")
library(dbplyr)
data %>% ggplot(aes(x=Outcome, y=Pregnancies, fill=Outcome))geom_boxplot()+ggtitle("Boxplot of Pregnancies for PIMA data")
data %>% ggplot(aes(x=Outcome, y="Pregnancies", fill=Outcome))geom_boxplot()+ggtitle("Boxplot of Pregnancies for PIMA data")
data %>% ggplot(aes(x=Outcome, y=Pregnancies, fill=Outcome))geom_boxplot()+ggtitle("Boxplot of Pregnancies for PIMA data")
model <- naive_bayes(Outcome~., data=train)
model
p<-predict(model, train, type = 'prob')
head(cbind(p,train))
p3 <-predict(model, train)
(tab1 <-table(p3, train$Outcome))
1-sum(diag(tab))/sum(tab1)
1-sum(diag(tab1))/sum(tab1)
p4<-predict(model, test)
(tab2 <-table(p4,test$Outcome))
1-sum(diag(tab2))/sum(tab2)
model <-naive_bayes(Outcome~.,data=train, usekernel = T)
model
plot(model)
p5 <- predict(model, train)
(tab3 <-table(p5, train$Outcome))
1-sum(diag(tab3))/sum(tab3)
p6<-predict(model, test)
(tab4 <-table(p6, test$Outcome))
1-sum(diag(tab4))/sum(tab4)
direvtory getwd()
directory getwd()
directory
getwd()
library(readxl)
pharmaceutical_sales_demand <- read_excel("Downloads/pharmaceutical-sales-demand.xlsx")
View(pharmaceutical_sales_demand)
library(ggplot2)
install.packages("forecast")
library(forecast)
library(tidyverse)
install.packages(prophet)
install.packages("prophet")
library(prophet)
library(lubridate)
library(scales)
str(pharmaceutical_sales_demand)
psd <- read_excel("Downloads/pharmaceutical-sales-demand.xlsx")
str(psd)
psd$`Stock Demand`<- as.numeric(psd$`Stock Demand`)
psd[is.na(psd)] <- 0
psd <- read_excel("Downloads/pharmaceutical-sales-demand.xlsx")
library(readxl)
psd <- read_excel("Downloads/pharmaceutical-sales-demand.xlsx")
install.packages("forecast")
library(forecast)
library(ggplot2)
library(scales)
library(tidyverse)
library(prophet)
library(lubridate)
str(psd)
sum(is.na(psd))
df <- psd %>%
group_by(Date) %>%
summarise('Stock Demand'=sum('Stock Demand'))
df <- psd %>%
group_by(Date) %>%
summarise(Stock Demand=sum(Stock Demand))
psd$Date <- ymd(psd$Date)
str(psd)
df <- psd %>%
group_by(Date) %>%
summarise('Stock Demand'=sum('Stock Demand'))
summarise(Stock Demand"=sum("Stock Demand"))
summarise("Stock Demand"=sum("Stock Demand"))
str
library(ggplot2)
library(lubridate)
library(prophet)
library(scales)
library(tidyverse)
library(readxl)
psd <- read_excel("Downloads/psd.xlsx")
str(psd)
psd$Date<-ymd(psd$Date)
str(psd)
df<- psd %>%
group_by(Date) %>%
summarise(Stock_Demand=sum(Stock_Demand))
ggplot(df, aes(x=Date, y=Stock_Demand))
ggplot(df, aes(x=Date, y=Stock_Demand)) + geom_bar(stat="identity")
df$Date <- floor_date(df$Date, "month")
plot(psd)
